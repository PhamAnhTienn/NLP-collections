{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1423,"sourceType":"datasetVersion","datasetId":747}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-07T12:58:39.087129Z","iopub.execute_input":"2024-09-07T12:58:39.088049Z","iopub.status.idle":"2024-09-07T12:58:39.453944Z","shell.execute_reply.started":"2024-09-07T12:58:39.087998Z","shell.execute_reply":"2024-09-07T12:58:39.453162Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/question-pairs-dataset/questions.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2024-09-07T12:58:50.782248Z","iopub.execute_input":"2024-09-07T12:58:50.782656Z","iopub.status.idle":"2024-09-07T12:58:51.849086Z","shell.execute_reply.started":"2024-09-07T12:58:50.782616Z","shell.execute_reply":"2024-09-07T12:58:51.848153Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"            id    qid1    qid2  \\\n0            0       1       2   \n1            1       3       4   \n2            2       5       6   \n3            3       7       8   \n4            4       9      10   \n...        ...     ...     ...   \n404346  404346  789792  789793   \n404347  404347  789794  789795   \n404348  404348  789796  789797   \n404349  404349  789798  789799   \n404350  404350  789800  789801   \n\n                                                question1  \\\n0       What is the step by step guide to invest in sh...   \n1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2       How can I increase the speed of my internet co...   \n3       Why am I mentally very lonely? How can I solve...   \n4       Which one dissolve in water quikly sugar, salt...   \n...                                                   ...   \n404346  How many keywords are there in the Racket prog...   \n404347          Do you believe there is life after death?   \n404348                                  What is one coin?   \n404349  What is the approx annual cost of living while...   \n404350              What is like to have sex with cousin?   \n\n                                                question2  is_duplicate  \n0       What is the step by step guide to invest in sh...             0  \n1       What would happen if the Indian government sto...             0  \n2       How can Internet speed be increased by hacking...             0  \n3       Find the remainder when [math]23^{24}[/math] i...             0  \n4                 Which fish would survive in salt water?             0  \n...                                                   ...           ...  \n404346  How many keywords are there in PERL Programmin...             0  \n404347         Is it true that there is life after death?             1  \n404348                                  What's this coin?             0  \n404349  I am having little hairfall problem but I want...             0  \n404350      What is it like to have sex with your cousin?             0  \n\n[404351 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>404346</th>\n      <td>404346</td>\n      <td>789792</td>\n      <td>789793</td>\n      <td>How many keywords are there in the Racket prog...</td>\n      <td>How many keywords are there in PERL Programmin...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>404347</th>\n      <td>404347</td>\n      <td>789794</td>\n      <td>789795</td>\n      <td>Do you believe there is life after death?</td>\n      <td>Is it true that there is life after death?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>404348</th>\n      <td>404348</td>\n      <td>789796</td>\n      <td>789797</td>\n      <td>What is one coin?</td>\n      <td>What's this coin?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>404349</th>\n      <td>404349</td>\n      <td>789798</td>\n      <td>789799</td>\n      <td>What is the approx annual cost of living while...</td>\n      <td>I am having little hairfall problem but I want...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>404350</th>\n      <td>404350</td>\n      <td>789800</td>\n      <td>789801</td>\n      <td>What is like to have sex with cousin?</td>\n      <td>What is it like to have sex with your cousin?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>404351 rows Ã— 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_len = 300000\ntest_len = 10*1024\ntrain_data = data[:train_len]\ntest_data = data[train_len : train_len + test_len]\nprint(\"Train set\", len(train_data), \"Test set\", len(test_data))\ndel(data)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T12:58:56.017649Z","iopub.execute_input":"2024-09-07T12:58:56.018505Z","iopub.status.idle":"2024-09-07T12:58:56.024348Z","shell.execute_reply.started":"2024-09-07T12:58:56.018445Z","shell.execute_reply":"2024-09-07T12:58:56.023531Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Train set 300000 Test set 10240\n","output_type":"stream"}]},{"cell_type":"code","source":"#selected duplicate questions to train model\nduplicate_index = (train_data['is_duplicate'] == 1).to_numpy()\nduplicate_index = [i for i, x in enumerate(duplicate_index) if x]\nprint('Number of duplicate questions: ', len(duplicate_index))\nduplicate_index[:10]","metadata":{"execution":{"iopub.status.busy":"2024-09-07T12:58:58.622904Z","iopub.execute_input":"2024-09-07T12:58:58.623297Z","iopub.status.idle":"2024-09-07T12:58:58.671267Z","shell.execute_reply.started":"2024-09-07T12:58:58.623257Z","shell.execute_reply":"2024-09-07T12:58:58.670436Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Number of duplicate questions:  111486\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[5, 7, 11, 12, 13, 15, 16, 18, 20, 29]"},"metadata":{}}]},{"cell_type":"code","source":"q1_train_data = np.array(train_data['question1'][duplicate_index])\nq2_train_data = np.array(train_data['question2'][duplicate_index])\n\nq1_test_data = np.array(test_data['question1'])\nq2_test_data = np.array(test_data['question2'])\ny_test = np.array(test_data['is_duplicate'])","metadata":{"execution":{"iopub.status.busy":"2024-09-07T12:59:01.420660Z","iopub.execute_input":"2024-09-07T12:59:01.421046Z","iopub.status.idle":"2024-09-07T12:59:01.479497Z","shell.execute_reply.started":"2024-09-07T12:59:01.421010Z","shell.execute_reply":"2024-09-07T12:59:01.478536Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom collections import defaultdict\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Initialize the tokenizer\ntokenizer = Tokenizer(oov_token=\"<OOV>\") \ncombined_train_words = q1_train_data + q2_train_data\n\n# Fit tokenizer on the training data\ntokenizer.fit_on_texts(combined_train_words)\nvocab_size = len(tokenizer.word_index) + 1 \nprint('The length of the vocabulary is:', vocab_size)\n\nvocab = defaultdict(lambda: tokenizer.word_index.get(\"<OOV>\", 0), tokenizer.word_index)\n\n# Tokenize and convert questions to sequences\nQ1_train_sequences = tokenizer.texts_to_sequences(q1_train_data)\nQ2_train_sequences = tokenizer.texts_to_sequences(q2_train_data)\nQ1_test_sequences = tokenizer.texts_to_sequences(q1_test_data)\nQ2_test_sequences = tokenizer.texts_to_sequences(q2_test_data)\n\n# Pad sequences to ensure they are of equal length\nQ1_train_padded = pad_sequences(Q1_train_sequences, padding='post')\nQ2_train_padded = pad_sequences(Q2_train_sequences, padding='post')\nQ1_test_padded = pad_sequences(Q1_test_sequences, padding='post')\nQ2_test_padded = pad_sequences(Q2_test_sequences, padding='post')\n\n# Split the training data into training and validation sets\ntrain_Q1, val_Q1, train_Q2, val_Q2 = train_test_split(Q1_train_padded, Q2_train_padded, test_size=0.2, random_state=42)\n\n# Print lengths and information\nprint('Train set has reduced to:', len(train_Q1))\nprint('Test set length:', len(Q1_test_padded))\nprint('Number of duplicate questions:', len(Q1_train_padded))\nprint(\"The length of the training set is:\", len(train_Q1))\nprint(\"The length of the validation set is:\", len(val_Q1))","metadata":{"execution":{"iopub.status.busy":"2024-09-07T13:46:55.159026Z","iopub.execute_input":"2024-09-07T13:46:55.160061Z","iopub.status.idle":"2024-09-07T13:47:02.777821Z","shell.execute_reply.started":"2024-09-07T13:46:55.160016Z","shell.execute_reply":"2024-09-07T13:47:02.776870Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"The length of the vocabulary is: 28311\nTrain set has reduced to: 89188\nTest set length: 10240\nNumber of duplicate questions: 111486\nThe length of the training set is: 89188\nThe length of the validation set is: 22298\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nclass QuestionDuplicateDataset(Dataset):\n    def __init__(self, q1, q2):\n        self.q1 = q1\n        self.q2 = q2\n    \n    def __len__(self):\n        return len(self.q1)\n    \n    def __getitem__(self, idx):\n        return self.q1[idx], self.q2[idx]\n\ntrain_dataset = QuestionDuplicateDataset(train_Q1, train_Q2)\nval_dataset = QuestionDuplicateDataset(val_Q1, val_Q2)\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\ntest_loader = DataLoader(val_dataset, batch_size=128, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T13:32:01.385307Z","iopub.execute_input":"2024-09-07T13:32:01.386155Z","iopub.status.idle":"2024-09-07T13:32:01.393966Z","shell.execute_reply.started":"2024-09-07T13:32:01.386112Z","shell.execute_reply":"2024-09-07T13:32:01.393027Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#define model\nclass Siamese(nn.Module):\n    def __init__(self, vocab_size=41699, d_model = 128):\n        super(Siamese, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, d_model)\n        self.lstm = nn.LSTM(d_model, d_model, batch_first=True)\n        self.d_model = d_model\n    \n    def forward(self, q1, q2):\n        q1_processed = self.process(q1)\n        q2_processed = self.process(q2)\n\n        return q1_processed, q2_processed\n    \n    def process(self, x):\n        #embedding\n        x = self.embedding(x)\n        #x shape: [batch_size, seq_len, d_model]\n        \n        #LSTM with hidden state and cell state\n        x, (hn, cn) = self.lstm(x)\n        #x shape: [batch_size, seq_len, d_model]\n        \n        #mean\n        x = torch.mean(x, dim=1)\n        #x shape: [batch_size, d_model]\n    \n        #normalize\n        x = F.normalize(x, p=2, dim=1)\n        #x shape: [batch_size, d_model]\n        return x\n\nmodel = Siamese()\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T12:59:41.833184Z","iopub.execute_input":"2024-09-07T12:59:41.833611Z","iopub.status.idle":"2024-09-07T12:59:41.920813Z","shell.execute_reply.started":"2024-09-07T12:59:41.833573Z","shell.execute_reply":"2024-09-07T12:59:41.919813Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Siamese(\n  (embedding): Embedding(41699, 128)\n  (lstm): LSTM(128, 128, batch_first=True)\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\\begin{align}\n \\mathcal{Loss_{1}(A,P,N)} &=\\max \\left( -cos(A,P)  + mean_{neg} +\\alpha, 0\\right) \\\\\n \\mathcal{Loss_{2}(A,P,N)} &=\\max \\left( -cos(A,P)  + closest_{neg} +\\alpha, 0\\right) \\\\\n\\mathcal{Loss(A,P,N)} &= mean(Loss_1 + Loss_2) \\\\\n\\end{align}","metadata":{}},{"cell_type":"code","source":"#define loss function\ndef TripletLossFn(v1, v2, margin=0.25):\n    scores = F.cosine_similarity(v1.unsqueeze(1), v2.unsqueeze(0), dim=-1)\n    #shape: [batch_size, batch_size]\n    batch_size = len(scores)\n    \n    positive = torch.diagonal(scores)\n    #shape: [batch_size]\n    eye = torch.eye(batch_size, device=scores.device)\n    #identity matrix shape: [batch_size, batch_size]\n    negative_zero_on_duplicate = scores * (1.0 - eye)\n    #shape: [batch_size, batch_size]\n    mean_negative = torch.sum(negative_zero_on_duplicate, dim=1) / (batch_size - 1)\n    #shape: [batch_size]\n    closest_negative = torch.max(negative_zero_on_duplicate, dim=1).values\n    #shape: [batch_size]\n    triplet_loss1 = torch.clamp(margin - positive + closest_negative, min=0.0)\n    #shape: [batch_size]\n    triplet_loss2 = torch.clamp(margin - positive + mean_negative, min=0.0)\n    #shape: [batch_size]\n    triplet_loss = torch.sum(triplet_loss1 + triplet_loss2)\n    #scalar\n    return triplet_loss","metadata":{"execution":{"iopub.status.busy":"2024-09-07T12:59:47.623760Z","iopub.execute_input":"2024-09-07T12:59:47.624120Z","iopub.status.idle":"2024-09-07T12:59:47.631974Z","shell.execute_reply.started":"2024-09-07T12:59:47.624087Z","shell.execute_reply":"2024-09-07T12:59:47.630842Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train_model(model, train_loader, val_loader, epochs=10, learning_rate=0.01, margin=0.25):\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    \n    for epoch in range(epochs):\n        model.train()\n        \n        running_loss = 0.0\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n        \n        for batch in progress_bar:\n            q1, q2 = batch\n            q1, q2 = q1.to(device), q2.to(device)\n            \n            optimizer.zero_grad()\n\n            v1, v2 = model(q1, q2)\n\n            loss = TripletLossFn(v1, v2, margin=margin)\n\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            progress_bar.set_postfix(loss=running_loss / len(train_loader))\n        \n        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}\")\n        \n        # Validation\n        validate_model(model, val_loader)\n\ndef validate_model(model, val_loader):\n    model.eval()  \n    val_loss = 0.0\n    with torch.no_grad():\n        for batch in val_loader:\n            q1, q2 = batch\n            q1, q2 = q1.to(device), q2.to(device)\n\n            v1, v2 = model(q1, q2)\n\n            loss = TripletLossFn(v1, v2)\n            val_loss += loss.item()\n\n    print(f\"Validation Loss: {val_loss/len(val_loader)}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-07T13:32:30.644113Z","iopub.execute_input":"2024-09-07T13:32:30.644511Z","iopub.status.idle":"2024-09-07T13:32:30.655861Z","shell.execute_reply.started":"2024-09-07T13:32:30.644457Z","shell.execute_reply":"2024-09-07T13:32:30.654829Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\nmodel = Siamese().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T13:32:33.850300Z","iopub.execute_input":"2024-09-07T13:32:33.851002Z","iopub.status.idle":"2024-09-07T13:32:33.915595Z","shell.execute_reply.started":"2024-09-07T13:32:33.850959Z","shell.execute_reply":"2024-09-07T13:32:33.914656Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"#train model\ntrain_model(model, train_loader, test_loader, epochs=10, learning_rate=0.001, margin=0.25)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T13:32:35.890799Z","iopub.execute_input":"2024-09-07T13:32:35.891164Z","iopub.status.idle":"2024-09-07T13:34:18.964806Z","shell.execute_reply.started":"2024-09-07T13:32:35.891130Z","shell.execute_reply":"2024-09-07T13:34:18.963853Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 697/697 [00:09<00:00, 73.34it/s, loss=9.32]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/10], Loss: 9.32205470973142\nValidation Loss: 6.02158684355872\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 697/697 [00:09<00:00, 73.89it/s, loss=4.96] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/10], Loss: 4.961131506020917\nValidation Loss: 4.861126567295619\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 697/697 [00:09<00:00, 73.38it/s, loss=3.98] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/10], Loss: 3.9785283008641117\nValidation Loss: 4.454091246298381\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 697/697 [00:09<00:00, 73.66it/s, loss=3.52] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/10], Loss: 3.5248368255890252\nValidation Loss: 4.304513124397823\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 697/697 [00:09<00:00, 73.74it/s, loss=3.22] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/10], Loss: 3.217541006066365\nValidation Loss: 4.13596147945949\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 697/697 [00:09<00:00, 73.76it/s, loss=3]    \n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/10], Loss: 2.9974023468012105\nValidation Loss: 3.849488261767796\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 697/697 [00:09<00:00, 73.93it/s, loss=2.83] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/10], Loss: 2.83347126033419\nValidation Loss: 3.8568617675134114\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 697/697 [00:09<00:00, 73.68it/s, loss=2.66] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/10], Loss: 2.6576051110858727\nValidation Loss: 3.7236525538989476\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 697/697 [00:09<00:00, 73.58it/s, loss=2.6]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/10], Loss: 2.5971395254477194\nValidation Loss: 3.6846274985585894\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 697/697 [00:09<00:00, 73.77it/s, loss=2.55] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/10], Loss: 2.550795706777354\nValidation Loss: 3.7308007631983076\n","output_type":"stream"}]},{"cell_type":"code","source":"#test model\ndef classify(test_Q1, test_Q2, y, threshold, model, vocab, batch_size=64):\n    model.eval() \n    accuracy = 0\n    total = len(test_Q1)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    for i in range(0, total, batch_size):\n        q1_batch = torch.tensor(test_Q1[i:i + batch_size]).to(device)\n        q2_batch = torch.tensor(test_Q2[i:i + batch_size]).to(device)\n        y_batch = torch.tensor(y[i:i + batch_size]).to(device)\n\n        with torch.no_grad():\n            v1, v2 = model(q1_batch, q2_batch)\n\n        for j in range(len(q1_batch)):\n            #cosine similarity\n            d = torch.dot(v1[j], v2[j]) / (torch.norm(v1[j]) * torch.norm(v2[j]))\n            # Check if the cosine similarity is greater than the threshold\n            res = d.item() > threshold\n            # Increment accuracy if prediction matches actual label\n            accuracy += (y_batch[j].item() == res)\n\n    accuracy = accuracy / total\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2024-09-07T13:34:45.336471Z","iopub.execute_input":"2024-09-07T13:34:45.337341Z","iopub.status.idle":"2024-09-07T13:34:45.346254Z","shell.execute_reply.started":"2024-09-07T13:34:45.337300Z","shell.execute_reply":"2024-09-07T13:34:45.345177Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"accuracy = classify(Q1_test_padded, Q2_test_padded, y_test, 0.7, model, vocab, batch_size = 512)\nprint(\"Accuracy\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T13:34:48.498685Z","iopub.execute_input":"2024-09-07T13:34:48.499066Z","iopub.status.idle":"2024-09-07T13:34:50.204971Z","shell.execute_reply.started":"2024-09-07T13:34:48.499031Z","shell.execute_reply":"2024-09-07T13:34:50.204123Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Accuracy 0.701171875\n","output_type":"stream"}]},{"cell_type":"code","source":"#Check with my own example\ndef predict(question1, question2, threshold, model, verbose=False):\n    q1_sequence = tokenizer.texts_to_sequences([question1])\n    q2_sequence = tokenizer.texts_to_sequences([question2])\n\n    q1_padded = pad_sequences(q1_sequence, padding='post')\n    q2_padded = pad_sequences(q2_sequence, padding='post')\n\n    device = next(model.parameters()).device \n    q1_tensor = torch.tensor(q1_padded, dtype=torch.long).to(device)\n    q2_tensor = torch.tensor(q2_padded, dtype=torch.long).to(device)\n\n    with torch.no_grad():\n        v1, v2 = model(q1_tensor, q2_tensor)\n\n    d = np.dot(v1[0].cpu().numpy(), v2[0].cpu().numpy().T)\n\n    result = \"Duplicate\" if d > threshold else \"Non-duplicate\"\n\n    if verbose:\n        print(\"d   =\", d)\n        #print(\"result =\", result)\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-09-07T14:01:51.718860Z","iopub.execute_input":"2024-09-07T14:01:51.719628Z","iopub.status.idle":"2024-09-07T14:01:51.727371Z","shell.execute_reply.started":"2024-09-07T14:01:51.719587Z","shell.execute_reply":"2024-09-07T14:01:51.726399Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"question1 = \"When will I see you?\"\nquestion2 = \"When can I see you again?\"\n\npredict(question1, question2, 0.7, model, True)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T14:01:53.262654Z","iopub.execute_input":"2024-09-07T14:01:53.263563Z","iopub.status.idle":"2024-09-07T14:01:53.272465Z","shell.execute_reply.started":"2024-09-07T14:01:53.263516Z","shell.execute_reply":"2024-09-07T14:01:53.271606Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"d   = 0.80519843\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"'Duplicate'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}